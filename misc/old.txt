async function whisperFetch(uri) {
    var url = "https://api.openai.com/v1/audio/transcriptions";
		// var url = "https://api.openai.com/v1/completions";
    var bearer = 'Bearer ' + OPENAI_API_KEY

	

    const formData = new FormData()
		// formData.append('file', file, "file.m4a");
		// formData.append("prompt", "hello");
		// formData.append("file", file, "test.mp4")

		formData.append('file', {
      uri: uri,
      type: 'audio/mp4',
      name: 'audio.m4a'
    });

    formData.append("model", "whisper-1");
		// formData.append("response_format", "text")
		console.log(formData)
    // const header = {
    //     'Authorization': bearer,
    //     "Content-Type": "multipart/form-data"
    // }
    
    // const options = {
    //     method: 'POST',
    //     headers: header,
    //     body: form
    //   }
    // const requestOptions = {
    //   method: "POST",
    //   headers: {
    //       Authorization: `Bearer ${OPENAI_API_KEY}`,
		// 			"Content-Type": "application/json",
    //     },
    //     body: formData,
    // };
    // result = await fetch(url, requestOptions);


    // result = await fetch(url, {
    //     method: 'POST',
    //     headers: {
    //         'Authorization': bearer,
    //         "Content-Type": "application/json"
    //     },
    //     body: JSON.stringify({
		// 			"prompt": "how are you",
    //       "model": "text-davinci-003",
    //     })
    // })

		result = await fetch(url, {
			method: 'POST',
			headers: {
					'Authorization': bearer,
					"Content-Type": "multipart/form-data"
			},
			body: formData
			
	})

    return result
}




function base64toBlob(base64Data, contentType) {
    contentType = contentType || '';
    var sliceSize = 1024;
    var byteCharacters = atob(base64Data);
    var bytesLength = byteCharacters.length;
    // var slicesCount = Math.ceil(bytesLength / sliceSize);
    var slicesCount = Math.ceil(bytesLength / sliceSize);
    var byteArrays = new Array(slicesCount);

    for (var sliceIndex = 0; sliceIndex < slicesCount; ++sliceIndex) {
        var begin = sliceIndex * sliceSize;
        var end = Math.min(begin + sliceSize, bytesLength);

        var bytes = new Array(end - begin);
        for (var offset = begin, i = 0; offset < end; ++i, ++offset) {
            bytes[i] = byteCharacters[offset].charCodeAt(0);
        }
        byteArrays[sliceIndex] = new Uint8Array(bytes);
    }
    // return byteArrays
    return new Blob(byteArrays, { type: contentType });
}

export const transcribeAudio = async (req) =>  {
    res = {
        status: {
          code: 0,
          error: {
          message: "",
          }
        },
        result: ""
    }
  if (!configuration.apiKey) {
    console.warn("No API key")
    return;
  }

  const uri = req.uri || '';
//   const audio_file = readFile(filename)

  console.log("uri: " + uri)
  if (uri) {
    console.log("Audio exists ")
  } else {
    console.log("Audio does not exist")
    return
  }

  try {
    // console.log("pre fetch")
    // blob = await fetch(filename)
    // console.log("past fetch")
    // console.log(uri)
    // const data = await FileSystem.readAsStringAsync("file://test.txt")
    // const [{ localUri }] = await Asset.loadAsync(
    //     require("./samantha.mp3")
    // );

    // console.log("asset = " + await localUri)
    // "data:audio/mp3;base64," +
    base64 = await FileSystem.readAsStringAsync(uri, { encoding: FileSystem.EncodingType.Base64 })
		// console.log(base64.substring(0,10))
    // const buffer = Buffer.from(recordingBase64, "base64")
    // const blob = new Blob([buffer], { type:'audio/mp4' })
    // const file = new File([blob],'test.mp4', {type:'audio/mp4'})
    // blob = await createBlob(base64)
		uriFetch = await fetch(uri)
		uriBlob = await uriFetch.blob()
    console.log("blob")
    console.log(uriBlob.type)
		console.log(uriBlob)
		console.log(uriBlob.data.name)
    const file = new File([uriBlob],uriBlob.data.name, {type:uriBlob.data.type})
    // const file = new File([blob], "input.wav", { type: "audio/wav" });
    // console.log(file.name)
		console.log("file")
		console.log(file)
    // console.log(blob)
    // blob = base64toBlob(base64, "multipart/form-data")
    response = await whisperFetch(uri)
		console.log(response)
		resJson = await response.json()
		console.log(resJson)
    // console.log(resJson.choices[0].text)
    // return;
    

    //replay to test


    // const transcript = await openai.createTranscription(file, "whisper-1")
    
    // console.log('pls')
    return response;
    // res.message = transcript.data.text
  }
  catch(error) {
    // Consider adjusting the error handling logic for your use case
    if (error.response) {
      console.error(error.response.status, error.response.data);
      res.status(error.response.status).json(error.response.data);
    } else {
      console.error(`Error with OpenAI API request: ${error.message}`);
    }
  }
  return res;
}


async function createBlob(base64) {
//     const file = Buffer.from(
//         base64,
//         'base64'
//       )
// // now it is Buffer

//     // const blob = new Blob([file])
//     return new Blob()
//     return blob
    response = await (fetch("data:audio/mp3;base64," + base64))
    return response.blob()
}



      <TextInput style={styles.testInput}
        placeholder="Type a response"
        onChangeText={(e) => setPromptInput(e)}
        value = {promptInput}
      />

// newBlurState = (getBlurState(blurStates, key) == 100) ? 0 : 100;
                // console.log("new state: " + newBlurState)
                // console.log(blurStates)
                // newStates = {
                // 	...blurStates,
                // 	[key]: newBlurState
                // }

                // // blurStates.map((v, i) => {
                // // 	if (i == key) {
                // // 		return newBlurState;
                // // 	} else {
                // // 		return v;
                // // 	}
                // // });
                // console.log("changed state: " + newStates[key])
                // console.log(newStates)
                // setBlurStates(newStates)

function createAIBlock(text, key) {
		setBlurStates({
			...blurStates,
			[key]: 0
		})

		return (
		<TouchableOpacity key={key} onPress={() => {
			
			newBlurState = (getBlurState(blurStates, key) == 100) ? 0 : 100;
			console.log("new state: " + newBlurState)
			console.log(blurStates)
			newStates = {
				...blurStates,
				[key]: newBlurState
			}

			// blurStates.map((v, i) => {
			// 	if (i == key) {
			// 		return newBlurState;
			// 	} else {
			// 		return v;
			// 	}
			// });
			console.log("changed state: " + newStates[key])
			console.log(newStates)
			setBlurStates(newStates)
		}}>

			<BlurView intensity={getBlurState(blurStates, key)} style={[styles.conversationBlock, styles.aiResponse]}>
				<Text style={styles.label}>Gabriela P. Toro:</Text>
				<Text style={styles.result}>{text}</Text>
			</BlurView>
		</TouchableOpacity>
		)
	}

	function getBlurState(blurList, key) {
		return blurList[key]
	}